{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCADAA Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from scipy.integrate import odeint, solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from exercise2 import DGM_Layer, Net_DGM\n",
    "from exercise2 import FFN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LQR:\n",
    "    def __init__(self, H, M, sigma, alpha, alpha_s, C, D, R, T) -> None:\n",
    "        self.H = H \n",
    "        self.M = M\n",
    "        self.sigma = sigma\n",
    "        self.alpha = alpha \n",
    "        self.alpha_s = alpha_s\n",
    "        self.C = C \n",
    "        self.D = D \n",
    "        self.R = R\n",
    "        self.T = T\n",
    "\n",
    "    \n",
    "    # def ricatti_ode(self, t, S):\n",
    "    #     return (-2 * (np.transpose(self.H))@S.reshape(2,2) \n",
    "    #             + S.reshape(2,2)@(self.M)@(torch.inverse(self.D))@(self.M)@S.reshape(2,2) \n",
    "    #             - self.C).flatten()\n",
    "    \n",
    "    def riccati_ode(self, t, S_flat):\n",
    "        S = torch.tensor(S_flat).reshape((2, 2))  # Convert S_flat to a PyTorch tensor\n",
    "        dS = (-2 * (self.H.t() @ S) + S @ (self.M) @ (torch.inverse(self.D)) @ (self.M) @ S - self.C)\n",
    "        return dS.flatten().detach().numpy()\n",
    " \n",
    "    def solve_lqr(self, time_grid):\n",
    "        \"\"\"\n",
    "        Solves the LQR problem by integrating the \n",
    "        Riccati equation backwards in time.\n",
    "        \"\"\"\n",
    "        # Time points (reversed for backward integration)\n",
    "        # t_points = np.linspace(0, self.T, 1000)[::-1]  \n",
    "        intial_cond = self.R.flatten().detach().numpy()\n",
    "\n",
    "        sol = solve_ivp(\n",
    "            self.riccati_ode, [self.T.item(), time_grid[0].item()], \n",
    "            intial_cond, t_eval=time_grid.numpy()[::-1], method='RK45'\n",
    "            )\n",
    "        \n",
    "        # S = [torch.tensor(sol.y[:, i].reshape((2, 2))) for i in range(len(sol.t))]\n",
    "        S = torch.tensor(sol.y)\n",
    "\n",
    "        return S\n",
    "\n",
    "    def visualize_results(self, t_points, S):\n",
    "        \"\"\"\n",
    "        Visualizes the solution of the Riccati equation \n",
    "        or the state/control trajectories.\n",
    "        \"\"\"\n",
    "        # S_00 = [s[0, 0].item() for s in S]\n",
    "        plt.plot(t_points, S[0, :])\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('S[0,0]')\n",
    "        plt.title('Solution of Riccati Equation over Time')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    def markov_control(self, time_grid, x):\n",
    "        S = self.solve_lqr(time_grid)\n",
    "        a = torch.tensor(len(t), dtype=torch.float32)\n",
    "        for t in range(len(t)):\n",
    "            for x in range(x.shape[1]):\n",
    "                a[t, x] = -inv(self.D) @ np.transpose(self.M) @ S[:, t].reshape(2, 2) * x[t, x]\n",
    "        return a\n",
    "\n",
    "\n",
    "    def value_function(self, t_batch, x_batch):\n",
    "        S = self.solve_lqr(t_batch)\n",
    "        v = torch.tensor(t_batch.size(0), dtype=torch.float32)\n",
    "\n",
    "        for i, t in enumerate(t_batch):\n",
    "            # Compute the first term\n",
    "            v1 = (np.transpose(x_batch) @ S[:, i].reshape(2, 2)) @ x_batch\n",
    "            # Compute the second term\n",
    "            trace = torch.trace(self.sigma @ np.transpose(self.sigma) @ S[:, i].reshape(2, 2))\n",
    "            v2 = (torch.tensor(self.T, dtype=torch.float32) - t) * trace\n",
    "        \n",
    "        # Compute the total value function: v(t, x) = x.transpose(S)x + integral_term\n",
    "        v = v1 + v2\n",
    "        \n",
    "        return v\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x3 and 2x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m x_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m2.0\u001b[39m], [\u001b[38;5;241m3.0\u001b[39m, \u001b[38;5;241m4.0\u001b[39m], [\u001b[38;5;241m5.0\u001b[39m, \u001b[38;5;241m6.0\u001b[39m]])  \u001b[38;5;66;03m# Sample spatial values\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Compute the value function\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m v_batch \u001b[38;5;241m=\u001b[39m \u001b[43mlqr_system\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Print the computed value function\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputed value function:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[40], line 71\u001b[0m, in \u001b[0;36mLQR.value_function\u001b[0;34m(self, t_batch, x_batch)\u001b[0m\n\u001b[1;32m     67\u001b[0m v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(t_batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(t_batch):\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# Compute the first term\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     v1 \u001b[38;5;241m=\u001b[39m (\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;241m@\u001b[39m x_batch\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Compute the second term\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     trace \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma \u001b[38;5;241m@\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma) \u001b[38;5;241m@\u001b[39m S[:, i]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x3 and 2x2)"
     ]
    }
   ],
   "source": [
    "# Example Usage:\n",
    "# Define problem matrices\n",
    "H = torch.tensor([[1, 0], [0, 1]], dtype=torch.float64)\n",
    "M = torch.tensor([[1, 0], [0, 1]], dtype=torch.float64)\n",
    "D = torch.tensor([[1, 0], [0, 1]], dtype=torch.float64)\n",
    "C = torch.tensor([[1, 0], [0, 1]], dtype=torch.float64)\n",
    "R = torch.tensor([[1, 0], [0, 1]], dtype=torch.float64)\n",
    "T = torch.tensor(10.0, dtype=torch.float64)\n",
    "sigma = np.array([[0, 0], [0, 0]])\n",
    "alpha = np.array([[0, 0], [0, 0]])\n",
    "alpha_s = np.array([[0, 0], [0, 0]])\n",
    "\n",
    "# Initialize LQRController\n",
    "# controller = LQRController(H, M, D, C, R, T)\n",
    "\n",
    "# Define time grid\n",
    "time_grid = torch.linspace(0, T, 1000)\n",
    "\n",
    "# Define state values\n",
    "x_values = torch.tensor([[[0.5, 0.5]], [[1.0, 1.0]]], dtype=torch.float64)  # Example state values\n",
    "\n",
    "lqr_system = LQR(H, M, sigma, alpha, alpha_s, C, D, R, T)\n",
    "S_solution = lqr_system.solve_lqr(time_grid)\n",
    "t_points = np.linspace(0, T, 1000)[::-1]  \n",
    "# lqr_system.visualize_results(t_points, S_solution)\n",
    "\n",
    "# Create sample input tensors\n",
    "t_batch = torch.tensor([0.5, 0.8, 1.0], dtype=torch.float32)  # Sample time values\n",
    "x_batch = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])  # Sample spatial values\n",
    "\n",
    "\n",
    "# Compute the value function\n",
    "v_batch = lqr_system.value_function(t_batch, x_batch)\n",
    "\n",
    "# Print the computed value function\n",
    "print(\"Computed value function:\")\n",
    "print(v_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqr_system = LQR(H, M, sigma, alpha, alpha_s, C, D, R, T)\n",
    "v = lqr_system.value_function(time_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate training data\n",
    "def generate_training_data(T, num_samples):\n",
    "    t = np.random.uniform(0, T, num_samples)\n",
    "    x = np.random.uniform(-3, 3, (num_samples, 2))\n",
    "    return t, x\n",
    "\n",
    "# Main training function\n",
    "def train_value_function(net, T, num_samples, num_epochs, lr):\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        t, x = generate_training_data(T, num_samples)\n",
    "\n",
    "        # this line needs to be fixed\n",
    "        v = lqr_system.value_function(time_grid)\n",
    "\n",
    "        input_data = torch.tensor(x, dtype=torch.float)\n",
    "        output_data = torch.tensor(v, dtype=torch.float)\n",
    "\n",
    "        outputs = net(input_data)\n",
    "        loss = criterion(outputs, output_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.title('Training Loss Plot')\n",
    "    plt.show()\n",
    "\n",
    "# Set parameters\n",
    "T = 1\n",
    "num_samples = 1000\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "# Initialize the neural network\n",
    "net = DGM_Layer()\n",
    "\n",
    "# Train the value function\n",
    "train_value_function(net, T, num_samples, num_epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sizes = [input_size, 100, 100, output_size]  # Specify sizes of input, hidden, and output layers\n",
    "ffn_model = FFN(sizes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
